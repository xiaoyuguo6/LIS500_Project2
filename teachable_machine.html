<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Teachable Machine Project</title>
    <link rel="stylesheet" href="teachable_machine.css">
</head>
<body>
    <header>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="about_us.html">About Us</a></li>
                <li><a href="resources.html">Resources</a></li>
                <li><a href="tech_hero.html">Tech Hero</a></li>
                <li><a href="teachable_machine.html">Teachable Machine</a></li>
            </ul>
        </nav>
    </header>

    <main>
        <!-- 第一部分：Project Overview -->
        <section class="project-overview">
            <h1>Project Overview</h1>
            <p>Our project was inspired by a shared passion for national parks and wildlife. As a team of three members who frequently explore national parks, we have always been fascinated by the diverse wildlife we encounter during our adventures. This love for nature served as the foundation for our project idea: utilizing the Teachable Machine platform to create a model capable of classifying three types of wildlife.

Through this project, we aimed to leverage technology to enhance the understanding and appreciation of wildlife, while also providing a practical tool for identifying these animals. The project not only reflects our enthusiasm for the natural world but also highlights how machine learning can be used to promote education and awareness in outdoor environments.</p>
        </section>

        <section class="reflections">
            <h1>Reflections</h1>
            <p>
                Working on this project provided first-hand insight into the complexities of developing ethical AI. While we were inspired by Buolamwini’s call for inclusivity, we also grappled with the limitations of our resources. Creating a perfectly unbiased model is nearly impossible, and trade-offs had to be made between fairness, accuracy, and feasibility. Buolamwini’s idea that "AI systems are mirrors of power" resonated deeply as we realized that even small decisions, such as how to label data or which metrics to prioritize, could reinforce or challenge existing power dynamics.
            </p>
            
            <h3><strong>Algorithmic Bias is Pervasive and Powerful</strong></h3>
            <p>
                Buolamwini's emphasis on how algorithms can reinforce systemic biases was a profound insight. Her example of facial recognition systems failing to identify women and people of color highlighted how data and design choices can marginalize communities. This inspired us to critically audit our own dataset, even though our project was relatively small in scale. For example, while using toy models of animals, we considered whether the specific designs of these toys—such as exaggerated or cartoonish features—might inadvertently lead to biases in our model's perception of real-world animals.
                We also explored how background diversity impacted classification accuracy. If all training images were taken against plain or similar backdrops, the model might struggle with generalizing to real-world environments. To mitigate this, we rotated toys against a variety of backgrounds, from patterned fabrics to textured walls. These steps reflected our awareness of the risks that unchecked biases, even in small-scale projects, could propagate into larger systems.
            </p>
            
            <h3><strong>Transparency and Accountability are Essential</strong></h3>
            <p>
                The book underscored the danger of "black box" algorithms, where decisions are made without providing insight into how they were reached. This highlighted the need for transparency in AI systems, driving us to document every step of our project and create user-friendly tools for exploring our model's strengths and limitations.
            </p>
            
            <h3><strong>AI Mirrors the Values of Its Creators</strong></h3>
            <p>
                AI systems inherently reflect the priorities and assumptions of their developers. This lesson pushed us to approach our project with a heightened awareness of the societal impacts of our design decisions, striving to create a model that upheld inclusivity and fairness.
            </p>
            
            <h3><strong>The Importance of Ethical Oversight</strong></h3>
            <p>
                Buolamwini's call for ethical governance and accountability resonated strongly. It became clear to us that deploying AI without oversight can deepen inequalities and harm marginalized groups. This reinforced our commitment to aligning our project with ethical principles, including transparency and justice.
            </p>
            
            <h3><strong>AI's Role in Shaping Humanity</strong></h3>
            <p>
                Buolamwini's idea that technology is reshaping what it means to be human challenged us to think about the broader implications of AI. As AI continues to influence creativity, decision-making, and power dynamics, it is vital to ensure it serves humanity rather than undermines it.
            </p>
        </section>
        <!-- 第三部分：Try Our Model -->
        <section class="try-model">
            <h2>Try Our Model</h2>
            <p>Click the button below to try our trained machine learning model:</p>
            <a href="https://teachablemachine.withgoogle.com/models/7q62EovFQ/" target="_blank" class="button">Click Here to Try Our Model</a>

            <div class="model-images">
                <h3>The Process</h3>
                <p>Our project focused on classifying three iconic animals from national parks: bighorn sheep, island foxes, and prairie dogs. To create the dataset, we used toy replicas purchased from official national park stores. These toys were held in front of a webcam, simulating real-world observations, and served as the sole source of input for training our model. By manually holding and rotating the toys, we captured multiple perspectives, enabling the model to learn to identify each animal effectively.</p>
                <img src="teachable_machine_1.png" alt="Teachable Machine Training Image 1" class="model-image">
                <h3>Export and Deployment</h3>
                <p>After completing the dataset, we trained the model using Teachable Machine's platform. The toy images captured via webcam allowed the model to learn efficiently and perform well during testing. Once trained, the model was deployed on Google’s cloud hosting. Testing the live system showed that the model could accurately identify the animals in real time, even under varied conditions, confirming the effectiveness of our approach.</p>
                <img src="teachable_machine_2.png" alt="Teachable Machine Training Image 2" class="model-image">
            </div>
        </section>

        <!-- 第四部分：See Our Codes -->
        <section class="model-code">
            <h2>See Our Codes & Weights</h2>
            <p>Explore the code and model weights behind our project:</p>
            <a href="https://drive.google.com/drive/folders/1SiMk45iStYJ5CwY3G2_JOLykshQnZVJY?dmr=1&ec=wgc-drive-hero-goto" target="_blank" class="button">View Code & Weights</a>
        </section>

        <!-- 第五部分：视频板块 -->
        <section class="video">
            <h2>Learn More from The Coding Train</h2>
            <p>Watch this video to learn more about creating image classification models with Teachable Machine.</p>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/kwcillcWOg0" frameborder="0" allowfullscreen></iframe>
        </section>
    </main>

    <footer>
        <p>&copy; Xiaoyu, Xiaoxue & Yixin. </p>
        <!-- Copyright information for the webpage -->
    </footer>
</body>
</html>
